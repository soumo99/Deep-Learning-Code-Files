{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOBaF01MLkD75svTYIIO2q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumo99/Deep-Learning-Code-Files/blob/main/Tensroflow_Keras_Code_Implementations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The integration of Keras and TensorFlow in deep learning projects provides a powerful and flexible framework for building, training, and deploying neural networks and other machine learning models. Keras serves as a high-level API for building and training models, while TensorFlow provides the computational backend for executing the operations defined in Keras models."
      ],
      "metadata": {
        "id": "HxU8b2QcUU5o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "EkW-2a485zyc",
        "outputId": "6e4f7a95-d2e5-468d-a795-198bda66dad4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'flatten'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-36b885cb67f5>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reshaping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mreshaped_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mflattened_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Concatenation and Splitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'flatten'"
          ]
        }
      ],
      "source": [
        "#Tensorflow basic operation\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define two tensors\n",
        "tensor1 = tf.constant([[1, 2], [3, 4]])\n",
        "tensor2 = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Mathematical Operations\n",
        "addition_result = tf.add(tensor1, tensor2)\n",
        "subtraction_result = tf.subtract(tensor1, tensor2)\n",
        "multiplication_result = tf.multiply(tensor1, tensor2)\n",
        "division_result = tf.divide(tensor1, tensor2)\n",
        "matrix_multiplication_result = tf.matmul(tensor1, tensor2)\n",
        "\n",
        "# Reduction Operations\n",
        "sum_result = tf.reduce_sum(tensor1)\n",
        "mean_result = tf.reduce_mean(tensor1)\n",
        "maximum_result = tf.reduce_max(tensor1)\n",
        "minimum_result = tf.reduce_min(tensor1)\n",
        "\n",
        "# Indexing and Slicing\n",
        "indexing_result = tf.gather(tensor1, indices=[0, 1])\n",
        "slicing_result = tf.slice(tensor1, begin=[0, 0], size=[1, 2])\n",
        "\n",
        "# Reshaping\n",
        "reshaped_tensor = tf.reshape(tensor1, shape=[1, 4])\n",
        "flattened_tensor = tf.flatten(tensor1)\n",
        "\n",
        "# Concatenation and Splitting\n",
        "concatenated_tensor = tf.concat([tensor1, tensor2], axis=0)\n",
        "split_tensors = tf.split(tensor1, num_or_size_splits=2, axis=1)\n",
        "\n",
        "# Element-wise Operations\n",
        "exponential_result = tf.exp(tensor1)\n",
        "square_root_result = tf.sqrt(tensor1)\n",
        "logarithm_result = tf.log(tensor1)\n",
        "\n",
        "# Comparison Operations\n",
        "equal_result = tf.equal(tensor1, tensor2)\n",
        "not_equal_result = tf.not_equal(tensor1, tensor2)\n",
        "greater_than_result = tf.greater(tensor1, tensor2)\n",
        "less_than_result = tf.less(tensor1, tensor2)\n",
        "\n",
        "# Random Operations\n",
        "random_normal_tensor = tf.random.normal(shape=(2, 2), mean=0.0, stddev=1.0)\n",
        "random_uniform_tensor = tf.random.uniform(shape=(2, 2), minval=0, maxval=1)\n",
        "shuffled_tensor = tf.random.shuffle(tensor1)\n",
        "\n",
        "# Start a TensorFlow session and run the computational graph\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    # Run the operations\n",
        "    addition_result_value, subtraction_result_value, multiplication_result_value, division_result_value, \\\n",
        "    matrix_multiplication_result_value, sum_result_value, mean_result_value, maximum_result_value, \\\n",
        "    minimum_result_value, indexing_result_value, slicing_result_value, reshaped_tensor_value, \\\n",
        "    flattened_tensor_value, concatenated_tensor_value, split_tensors_value, exponential_result_value, \\\n",
        "    square_root_result_value, logarithm_result_value, equal_result_value, not_equal_result_value, \\\n",
        "    greater_than_result_value, less_than_result_value, random_normal_tensor_value, random_uniform_tensor_value, \\\n",
        "    shuffled_tensor_value = sess.run([addition_result, subtraction_result, multiplication_result, division_result,\n",
        "                                      matrix_multiplication_result, sum_result, mean_result, maximum_result,\n",
        "                                      minimum_result, indexing_result, slicing_result, reshaped_tensor,\n",
        "                                      flattened_tensor, concatenated_tensor, split_tensors, exponential_result,\n",
        "                                      square_root_result, logarithm_result, equal_result, not_equal_result,\n",
        "                                      greater_than_result, less_than_result, random_normal_tensor,\n",
        "                                      random_uniform_tensor, shuffled_tensor])\n",
        "\n",
        "# Print the results\n",
        "print(\"Addition Result:\\n\", addition_result_value)\n",
        "print(\"Subtraction Result:\\n\", subtraction_result_value)\n",
        "print(\"Multiplication Result:\\n\", multiplication_result_value)\n",
        "print(\"Division Result:\\n\", division_result_value)\n",
        "print(\"Matrix Multiplication Result:\\n\", matrix_multiplication_result_value)\n",
        "print(\"Sum Result:\", sum_result_value)\n",
        "print(\"Mean Result:\", mean_result_value)\n",
        "print(\"Maximum Result:\", maximum_result_value)\n",
        "print(\"Minimum Result:\", minimum_result_value)\n",
        "print(\"Indexing Result:\\n\", indexing_result_value)\n",
        "print(\"Slicing Result:\\n\", slicing_result_value)\n",
        "print(\"Reshaped Tensor:\\n\", reshaped_tensor_value)\n",
        "print(\"Flattened Tensor:\", flattened_tensor_value)\n",
        "print(\"Concatenated Tensor:\\n\", concatenated_tensor_value)\n",
        "print(\"Split Tensors:\\n\", split_tensors_value)\n",
        "print(\"Exponential Result:\\n\", exponential_result_value)\n",
        "print(\"Square Root Result:\\n\", square_root_result_value)\n",
        "print(\"Logarithm Result:\\n\", logarithm_result_value)\n",
        "print(\"Equal Result:\\n\", equal_result_value)\n",
        "print(\"Not Equal Result:\\n\", not_equal_result_value)\n",
        "print(\"Greater Than Result:\\n\", greater_than_result_value)\n",
        "print(\"Less Than Result:\\n\", less_than_result_value)\n",
        "print(\"Random Normal Tensor:\\n\", random_normal_tensor_value)\n",
        "print(\"Random Uniform Tensor:\\n\", random_uniform_tensor_value)\n",
        "print(\"Shuffled Tensor:\\n\", shuffled_tensor_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras basic code implementaiton\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define a Sequential model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFF9thNb54oe",
        "outputId": "20514e77-d6ce-41fd-d2fd-50cbd1d24e1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50890 (198.79 KB)\n",
            "Trainable params: 50890 (198.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVxZiqTe5_K_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}